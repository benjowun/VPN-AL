%----------------------------------------------------------------
%
%  File    :  vpn_prelim.tex
%
%  Author  :  Keith Andrews, IICM, TU Graz, Austria
% 
%  Created :  22 Feb 96
% 
%  Changed :  19 Feb 2004
% 
%----------------------------------------------------------------

\chapter{Preliminaries}

\label{chap:Preliminaries}

\section{Deterministic Finite Automata}
A \ac{dfa} is a finite-state machine that is defined as a quintuple $D = \{S, s_0, \Sigma, \delta, F\}$ where $S$ is a finite set of states, $s_0 \in S$ is the initial state, $\Sigma$ is a finite set called the input alphabet, $\delta$ is the state-transition function $\delta \colon S \times \Sigma \rightarrow S$ that maps a state and an element of the input alphabet to another state in $S$ and $F$ is the set of accepting states. \Acp{dfa} do not have any output.

\section{Mealy Machines}
Mealy machines are a modeling formalism for reactive systems such as communication protocols. Mealy machines are finite-state machines in which each transition is labeled with an input and a corresponding output action. More formally, a Mealy machine is defined as a 6-tuple $M = \{S, s_0, \Sigma, O, \delta, \lambda\}$, where $S$ is a finite set of states, $s_0 \in S$ is the initial state, $\Sigma$ is a finite set called the input alphabet, $O$ is a finite set called the output alphabet, $\delta$ is the state-transition function $\delta \colon S \times \Sigma \rightarrow S$ that maps a state and an element of the input alphabet to another state in $S$. In other words, the choice of each new state is defined by the current state and an external input. Finally, $\lambda$ is the output function $\lambda \colon S \times \Sigma \rightarrow O$ which maps a state-input alphabet pair to an element of the output alphabet $O$. The main difference to a \ac{dfa} is, that Mealy machines have an output and \acp{dfa} do not. We use Mealy machines to model the state of learned \ac{ipsec} implementations.

\section{Automata Learning}
Automata learning refers to methods of learning the state model, or automaton, of a system through an algorithm or process. Automata learning algorithms generate a model that describes the behavior of the \ac{sul}. We differentiate between active and passive automata learning. In passive automata learning, models are learned based on a given data set describing the behavior of the \ac{sul}, e.g. log files. In contrast, in \ac{aal} the \ac{sul} is queried directly. In this paper, we will focus on \ac{aal} and will, moving on, be referring to it as automata learning or \ac{aal} interchangeably. 

One of the most influential AAL algorithms was introduced in 1987 by Dana Angluin, titled ``Learning regular sets from queries and counterexamples''~\cite{ANGLUIN198787}. In this seminal paper, Angluin introduced the concept of the \ac{mat} as well as an algorithm for learning regular languages from queries and counterexamples, called $L^*$. In it, a student questions a teacher and constructs a hypothesis based on its responses. The hypothesis is then tested through equivalence queries which check if the hypothesis correctly matches the regular language being learned. While the L* algorithm was originally designed to learn \acp{dfa}, it can be simply extended to work for Mealy machines by making use of the similarities between \acp{dfa} and Mealy machines~\cite{hungar2003domain, shahbaz2009inferring}. Variants of the $L^*$ algorithm are still used for learning deterministic automata to this day, e.g. by the AAL python library \textsc{AALpy} \cite{software:aalpy}. While the original $L^*$ algorithm was designed to learn \acp{dfa} formalizing regular languages, the algorithm can be extended to learn Mealy machines \cite{Niese2003AnIA}. While many modern implementations, including \textsc{AALpy} use improved versions of $L^*$, such as with advanced counter example processing by Rivest and Shapire~\cite{Rivest1993Inference}, fundamentally they still resemble the original algorithm by Angluin. 

The \ac{mat} concept is also used by other active learning algorithms. Kearns and Vazirani~\cite{KV1994} proposed an active learning algorithm that uses an underlying tree-based data structure called a classification tree to construct a model. We refer to their learning algorithm as $KV$. Published later than $L^*$, it boasts a more compact method of representing learned data, which, on average, leads to the $KV$ algorithm requiring less membership queries than $L^*$ to learn a model. Especially for learning internet protocols and other systems where communication with the \ac{sul} can be very time consuming, this can result in a significant performance increase. However, the $KV$ algorithm does on average require more equivalence queries to learn a system. Both algorithms used in this paper are briefly explained below.

\subsection{L\textsuperscript{*}}
$L^*$ uses the \ac{mat} framework to learn an unknown regular language $L$. This means, that we define both a learner and a teacher. The teacher must respond to two types of queries posed by the learner, namely membership and equivalence queries. Queries are built using a fixed input alphabet $\Sigma$ where $L \subseteq \Sigma^*$ must hold. Membership queries consist of a word $s \in \Sigma^*$ and must be answered with either ``yes'' if $s \in L$, or ``no'' if not. In other words, membership queries are used to check if a given word is part of the language being learned. The learner proposes a regular language $L\mathrm{prop}$ and sends it to the teacher as an equivalence query. The teacher must confirm if $L\mathrm{prop}$ is equivalent to $L$, answering with  ``yes'' if the equivalence holds true, or else returning a counterexample $c$ proving the two languages are different. So $c \in L\mathrm{prop} \iff c \notin L$. In other words, equivalence queries are used to verify if the learner has successfully learned the target language $L$ or if not, return a counterexample detailing the differences. The results of the membership queries are stored in an observation table $O = (S,E,T)$, where $S$ is a prefix-closed set of words representing candidates for states of $L_{prop}$, $E$ a suffix-closed set of words used to distinguish between candidates and $T$ a transition function $(S \cup S \cdot \Sigma) \cdot E \rightarrow {0,1}$, with $S \cdot \Sigma$ being the concatenation of words in $S$ with words in $\Sigma$ and $\cup$ referring to the union of two sets. Essentially, if visualized as a 2D array where the rows are labeled with elements in $(S \cup S \cdot \Sigma)$ and columns with elements in $E$, the entries in the table are ones, if the word created by appending the row-label to the column-label is accepted by $L$ and zeros if not. 

The goal of $L^*$ is to learn a \ac{dfa} acceptor for $L$ using the observation table. S-labeled rows correspond to states in the acceptor under construction. E-labeled columns represent individual membership query results. For the observation table to be transformable into a \ac{dfa} acceptor, it must first be closed and consistent.


\begin{lstlisting}[mathescape=true, float=b, caption=$L^*$ algorithm, label=lst:lstar]
	$\mathbf{Initialization}$: 
	Set observation table $O = (S,E,T)$ with $S,E = \{\epsilon\}$.
	$populate(O)$.
	
	$\mathbf{repeat}$:
		$\mathbf{while}$ $O$ is not closed or not consistent $\mathbf{do}$
			$\mathbf{if}$ $O$ is not closed $\mathbf{then}$
				choose $s_1 \in S, \sigma \in \Sigma$ such that
				$row(s_1 \cdot \sigma) \neq row(s) \; \forall s \in S$
				add $s_1 \cdot \sigma$ to $S$
				$populate(O)$
			$\mathbf{end}$
			$\mathbf{if}$ $O$ is not consistent $\mathbf{then}$
				choose $s_1, s_2 \in S, \sigma \in \Sigma$ and $e \in E$ such that
				$row(s_1) = row(s_2)$ and $T(s_1 \cdot \sigma \cdot e) \neq T(s_2 \cdot \sigma \cdot e)$
				add $\sigma \cdot e$ to $E$
				$populate(O)$
			$\mathbf{end}$		
		$\mathbf{end}$
		Construct $L_{prop}$ from $O$ and perform an equivalence query.	
		$\mathbf{if}$ query returns a counterexample $c$ $\mathbf{then}$
			add all prefixes of $c$ to $S$
			$populate(O)$
		$\mathbf{end}$
	$\mathbf{until}$ teacher replies "yes" to equivalence query $L_{prop} \equiv L$
	$\mathbf{return}$ $L_{prop}$
\end{lstlisting}

Closed is defined as for all $t \in S \cdot \Sigma$ there exists an $s \in S$ so that $row(t) = row(s)$. In other words, that no new information is gained by expanding the $S$-set by any word in $\Sigma$. If an observation is not closed, it is fixed by adding $t$ to $S$ and updating the table rows through more membership queries. 
Consistent means, that $\forall s_1, s_2 \,|\, row(s_1) = row(s_2) \implies \forall \sigma \in \Sigma \,|\, row(s_1 \cdot \sigma) = row(s_2 \cdot \sigma)$, or in other words, appending the same word to identical states should not result in different outcomes. If an observation table is inconsistent, it is made consistent again by adding another column to the table with the offending $\sigma$ as its label and again updating the table rows through more membership queries. 

Listing~\ref{lst:lstar} shows the workings of the basic $L^*$ algorithm by Angluin. At the start of the algorithm, the observation table is initialized with $S = E = \{\epsilon\}$ in Line 2. The function $populate(O)$ in Line 3 extends $T$ to $(S \cup S \cdot \Sigma) \cdot E$ by asking membership queries for all table entries still missing membership information. Next, until a equivalence query succeeds, the observation table is repeatedly brought to a closed and consistent state by expanding the $S$ and $E$ sets respectively as detailed previously. This occurs in the while loop in Line 6 until the observation table is brought to a closed and consistent state. Following this, $L_{prop}$ is constructed from $O$ and used in an equivalence query in Line 20. If the equivalence query returns ``yes'', the algorithm terminates, returning the learned \ac{dfa}. If not, the returned counterexample is used to update the observation table and the algorithm loops back to Line 5. 

\subsection{KV}
Another notable AAL algorithm is the KV algorithm published in 1994 by Kearns and Vazirani~\cite{KV1994}. It is designed to work with the same \ac{mat} framework as $L^*$, but aims to minimize the amount of membership queries needed to learn a finite automaton $M$. The $KV$ algorithm does this by organizing learned information in an ordered binary tree called a classification tree $C_T$ as opposed to the table structure utilized by $L^*$. As a trade-off, the $KV$ algorithm requires on average more equivalence queries than $L^*$. Intuitively, $L^*$ must perform membership queries for every entry in the observation table to differentiate between possible states, whereas $KV$ requires only a subset to distinguish them. 

In the $KV$ algorithm, learned data is stored in two sets called the access strings set $S$ and the distinguishing strings set $D$. The information contained is stored in a binary tree called the classification tree $C_T$. Every word $s \in S$ represents a distinct and unique state of the automaton $M$. In other words, any $s$ when applied starting in the initial state of $M$ leads to a unique state $M[s]$, where $M[s]$ signifies the state reached by applying $s$ to the finite automaton $M$. The distinguishing strings set is defined as the set of words $d \in D$ where for each pair $s,s' \in S, s \neq s'$ there exists a $d \in D$ such that either $M[s \cdot d]$ or $M[s' \cdot d]$ is an accepting state. $D$ is used to ensure that their are no ambiguous states. The binary tree $C_T$ is formed from $S,D$ by setting parent nodes to be words from $D$ and leaf nodes as words from $S$. The root node is set to the empty word $\epsilon$. For each node of the tree, starting from the root node, each right subtree contains access strings to accepting states while left subtrees contain access strings to rejecting states of $M$. Given a new word $s'$, we simply start at the root nodes, then sift down the tree by executing a membership query for $s' \cdot \lambda_1$ and depending on if the query returns ``yes'' or ``no'' continuing with the left or right subtree until we reach a leaf node labeled with $s$. If $s' = s$ then the states are equivalent, otherwise the classification tree is updated to include another leaf node representing the newly learned distinct state $s'$. The main learning loop of the $KV$ algorithm is shown in more detail in Listing~\ref{lst:kv}. Following the initialization of the classification table in Lines 2-5, new states learned from counterexamples are repeatedly added until an equivalence query is successful in Lines 8-14. The $Update(C_T,c)$ function in Line 14 adds a new leaf to the $C_T$ based on a counterexample $c$ returned from an equivalence query.

\begin{lstlisting}[mathescape=true, float=ht, caption=$KV$ algorithm, label=lst:kv]
	$\mathbf{Initialization}$: 
		Set root node of $C_T$ to $\epsilon$. 
		Perform membership query on $\epsilon$ to determine if the initial state is accepting or not.
		Construct hypothesis automaton $\hat M$ consisting of only the initial state, with self-transitions for all other transitions.
		Add two access strings $\epsilon$ and the counterexample $c$.
	
	$\mathbf{repeat}$:
		Construct hypothesis automaton $\hat M$ from $C_T$.
		Equivalence query($\hat M$)
		$\mathbf{if}$: query returns "yes" $\mathbf{then}$
			$\mathbf{return}$ $\hat M$
		$\mathbf{end}$
		
		$Update(C_T,c)$
	$\mathbf{end}$
	
\end{lstlisting}


\section{Fuzzing}
Fuzzing, or fuzz testing, is a technique in software testing in which lots of random, invalid or unexpected data is used as input for a program. The goal is to elicit crashes or other anomalous behavior from the \ac{sut} that might serve as an indication of a software bug. To this end, lots of data is generated and sent to the \ac{sut}. First used to test the reliability of Unix utilitis~\cite{miller1990empirical}, it can be applied to test the reliability and security of any system that takes input. While originally just a simple random text-generation program, modern fuzzers are often more complex and boast a variety of features. Modern fuzzers mainly differ on the method of data generation and can be roughly categorized as generation-based or mutation-based fuzzers. Generation-based fuzzers generate their data from scratch, whereas mutation-based fuzzers modify, or ``mutate'' existing data. Additionally, one can categorize fuzzers based on how much knowledge they have on the \ac{sut}, or in other words, how much information on the expected input structure is known by the fuzzer. How much relevant behavior of the \ac{sut} is actually reached and tested by a fuzzer is commonly referred to as the coverage of the fuzzer. To ensure that a fuzzer can test all relevant parts of a \ac{sut}, i.e. achieve good coverage, additional information on the structure of the \ac{sut} may be utilized. While the source code coverage of the \ac{sut} can be used as a suitable metric if it is available (white-box testing), in other scenarios where no source code is public (black-box testing), other methods of guaranteeing meaningful coverage are required. One possible solution, usable for black-box scenarios, could be to use a model representation of the \ac{sut} to generate more relevant inputs and therefore better coverage. This technique is known as model-based fuzzing and is the fuzzing technique used in this thesis. While fuzzers come in many different shapes and forms, their core function is usually the same in that test data is generated, executed on the \Ac{sut} and then the \ac{sut} is observed for strange behavior.

Two popular examples of fuzzers are \ac{afl}~\cite{zalewskiafl} and boofuzz~\cite{pereyda2019boofuzz}. \ac{afl} is a software fuzzer, written mainly in C, that uses genetic algorithms in combination with instrumentation to achieve high code coverage of the \Ac{sut}. The instrumentation has to be added to the the target by compiling the \ac{sut} using a custom compiler provided by \ac{afl}. \ac{afl} has been successfully used to find bugs in many high-profile projects such as OpenSSH~\footnote{https://lists.mindrot.org/pipermail/openssh-commits/2014-November/004134.html}, glibc~\footnote{https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=772705} and even linux memory management~\footnote{https://bugs.chromium.org/p/project-zero/issues/detail?id=1431}. 

\begin{figure}
	\centering
	\includegraphics[width=0.9\linewidth]{images/American_fuzzy_lop's_afl-fuzz_running_on_a_test_program}
	\caption{AFL fuzzer}
	\label{fig:americanfuzzylopsafl-fuzzrunningonatestprogram}
\end{figure}

Furthermore, boofuzz is a Python-based fuzzing library most commonly used for protocol fuzzing. As such, it does not require code instrumentation to function. Instead, it supports building blueprints of protocols to be fuzzed using primitives and blocks. These can be thought of as representations of various common components of protocols, such as data types including strings, integers and bytes, but also other common features, such as length fields, delimiters and checksums. These allow users to specify protocol requests to be sent to the \ac{sut} and explicitly mark which portions of the request should be fuzzed via settings in the primitives. Possible settings on a per primitive/block level include the maximum length of data to be generated while fuzzing and also if the element in question should be fuzzed at all, or just be left at a default values. The option to define which parts of a protocol will be fuzzed at a field-by-field level gives boofuzz a high degree of flexibility. The exact fuzz data generated by the framework depends on the used blocks and settings, and then creates mutations based on the specified protocol structure. For example, a string primitive uses a list of many ``bad'' strings as a basis for mutation, which it then concatenates, repeats and otherwise mutates. Additionally, the \ac{sut} can be monitored for crashes and other unexpected behavior and the framework can furthermore be instructed to restart or reset the \ac{sut} when needed. In this paper, we use boofuzz primitives to generate our values for fuzzing, as detailed in Chapter \ref{chap:Fuzzing}.

\begin{figure}
	\centering
	\includegraphics[width=0.9\linewidth]{images/boofuzz_control_center}
	\caption{Boofuzz fuzzer}
	\label{fig:boofuzzcontrolcenter}
\end{figure}

\newpage
\section{IPsec}
% TODO: More on VPNs in general

\ac{vpn}s are used to extend and or connect private networks across an insecure channel (usually the public internet). They can be used, e.g. to gain additional privacy from prying eyes such as Internet Server Providers, access to region-locked online content or secure remote access to company networks. Many different \ac{vpn} protocols exist, including PPTP, OpenVPN and Wireguard. Internet Protocol Security (\ac{ipsec}), is a \ac{vpn} layer 3 protocol suite used to securely communicate over an insecure channel. It is based on three sub-protocols, the \ac{ike} protocol, the \ac{ah} protocol and the \ac{esp} protocol. \ac{ike} is mainly used to handle authentication and to securely exchange as well as manage keys. Following a successful \ac{ike} round, either \ac{ah} or \ac{esp} is used to send packets securely between parties. The main difference between \ac{ah} and \ac{esp} is that \ac{ah} only ensures the integrity and authenticity of messages while \ac{esp} also ensures their confidentiality through encryption.

\begin{figure}[H]
\begin{centering}
	\begin{tikzpicture}[scale=1]
		\draw (-3,0) -- (-3,-9.2) (3,0) -- (3,-9.2);
		\node at (-3,.3) {Initiator};
		\node at (3,.3) {Responder};
		\draw[->] (-3,-1) -- node[midway,above] {ISAKMP SA \{proposals\}} (3,-1);
		\draw[<-] (-3,-2) -- node[midway,above] {ISAKMP SA \{proposal\}} (3,-2);
		\draw[->] (-3,-3) -- node[midway,above] {KE $\{pkey_i, nonce_i\}$} (3,-3);
		\draw[<-] (-3,-4) -- node[midway,above] {KE $\{pkey_r, nonce_r\}$} (3,-4);
		\draw[->] (-3,-5) -- node[midway,above] {AUTH $\{hash_i\}$} (3,-5);
		\draw[<-] (-3,-6) -- node[midway,above] {AUTH $\{hash_r\}$} (3,-6);
		\draw[->] (-3,-7) -- node[midway,above] {IPSEC SA \{proposals\}} (3,-7);
		\draw[<-] (-3,-8) -- node[midway,above] {IPSEC SA \{proposal\}} (3,-8);
		\draw[->] (-3,-9) -- node[midway,above] {ACK} (3,-9);
	\end{tikzpicture}
	\caption{IKEv1 between two parties}
	\label{fig:IKEv1}
\end{centering}
\end{figure}

The \ac{ike}v1 protocol works in two main phases, both relying on the \ac{isakmp}. Additionally, phase one can be configured to proceed in either Main Mode or Aggressive Mode. A typical exchange between two parties, an initiator (e.g. an employee connecting to a company network) and a responder (e.g. a company VPN server), using Main Mode for phase one and \ac{psk} authentication, can be seen in Figure \ref{fig:IKEv1}. In contrast, aggressive mode reduces the number of packets in phase one to only three. While faster, this method is considered to be less secure, as the authentication hashes are sent in clear text. In phase one (Main Mode), the initiator begins by sending a \ac{sa} to the responder. A \ac{sa} essentially details important security attributes required for a connection such as the encryption algorithm and key-size to use, as well as the authentication method and the used hashing algorithm. These options are bundled in containers called proposals, with each proposal describing a possible security configuration. While the initiator can send multiple proposals to give the responder more options to choose from, the responder must answer with only one proposal, provided both parties can agree upon one of the suggested proposals. This initial communication is denoted as \emph{ISAKMP SA} in Figure~\ref{fig:IKEv1} and also exchanges initiator/responder cookies, tokens used as identifiers for the remainder of the connection. Subsequently, the two parties perform a Diffie-Hellman key exchange, denoted as \emph{KE}, with the public key shorted to $pkey$, and send each other nonces used to generate a shared secret key \texttt{SKEYID} as detailed in Listing~\ref{lst:keying}. Here, \texttt{PSK} refers to the pre-shared key, \texttt{Ni/Nr} to the initiator/responder nonce and \texttt{CKY-I/CKY-R} to the initiator/responder identifier cookie. The symbol ``|'' is used to signify concatenation of bytes, not a logical or. Note that \ac{ike}v1 allows using various different authentication modes aside from PSK, including public key encryption and digital signatures. \texttt{SKEYID} is used as a seed key for all further session keys \texttt{SKEYID\_d}, \texttt{SKEYID\_a}, \texttt{SKEYID\_e}, with $g^{xy}$ referring to the previously calculated shared Diffie-Hellman secret and \texttt{prf} to a pseudo-random function (in our case, HMAC). 0, 1 and 2 are constants used to ensure that the resulting key material is different and unique for each type of key. Following a successful key exchange, all further messages of phase one and two are encrypted using a key derived from \texttt{SKEYID\_e} and \texttt{SKEYID\_a} for authentication. Finally, in the last section of phase one \emph{AUTH}, both parties exchange and verify hashes to confirm the key generation was successful. Once verification succeeds, a secure channel is created and used for phase two communication. If phase one uses Aggressive Mode, then only three packets are needed to reach phase two. While quicker, the downside of Aggressive Mode is that the communication of the hashed authentication material happens without encryption. This means, that using short \acp{psk} in combination with Aggressive Mode is inherently insecure, as the unencrypted hashes are vulnerable to brute-force attacks provided a short key-size~\footnote{https://nvd.nist.gov/vuln/detail/CVE-2018-5389}. The shorter phase two (Quick Mode) begins with another \ac{sa} exchange, labeled with \emph{IPSEC SA} in Figure~\ref{fig:IKEv1}. This time, however, the \ac{sa} describes the security parameters of the ensuing \ac{esp}/\ac{ah} communication and the data is sent authenticated and encrypted using the cryptographic material calculated in phase one. This is followed by a single acknowledge message, \emph{ACK}, from the initiator to confirm the agreed upon proposal. After the acknowledgment, all further communication is done via \ac{esp}/\ac{ah} packets, using \emph{SKEYID\_d} as keying material.

\begin{lstlisting}[float=ht, caption=IKE Keying, label=lst:keying]
	# For pre-shared keys: 
	SKEYID = prf(PSK, Ni_b | Nr_b)
	
	# to encrypt non-ISAKMP messages (ESP)
	SKEYID_d = prf(SKEYID, g^xy | CKY-I | CKY-R | 0)
	
	# to authenticate ISAKMP messages
	SKEYID_a = prf(SKEYID, SKEYID_d | g^xy | CKY-I | CKY-R | 1)
	
	# for further encryption of ISAKMP messages in phase two
	SKEYID_e = prf(SKEYID, SKEYID_a | g^xy | CKY-I | CKY-R | 2)
\end{lstlisting}

In addition to the packets shown in Figure~\ref{fig:IKEv1}, \ac{ike}v1 also specifies and uses so called \ac{isakmp} Informational Exchanges. Informational exchanges in \ac{ike}v1 are used to send \ac{isakmp} Notify or \ac{isakmp} Delete payloads. Following the key exchange in phase one, all Informational Exchanges are sent encrypted and authenticated. Prior, they are sent in plain. \ac{isakmp} Notify payloads are used to transmit various error and success codes, as well as for keep-alive messages. \ac{isakmp} Delete is used to inform the other communication partner, that a \ac{sa} has been deleted locally and request that they do the same, effectively closing a connection. 

Compared to other protocols, \ac{ipsec} offers a high degree of customizability, allowing it to be fitted for many use cases. However, in a cryptographic evaluation of the protocol, Ferguson and Schneier \textcite{ferguson1999cryptographic} criticize the complexity arising from the high degree of customizability as the biggest weakness of \ac{ipsec}. To address its main criticism, \ac{ipsec}-\ac{ike}v2 was introduced in RFC 7296 to replace \ac{ike}v1 \cite{kaufman2014internet}. Nevertheless, \ac{ipsec}-\ac{ike}v1 is still in wide-spread use to this day, with the largest router producer in Germany, AVM, still only supporting \ac{ike}v1 in their routers \cite{avm2022}. We use \ac{ipsec}-\ac{ike}v1 with Main Mode and \ac{esp} in this paper and focus on the \ac{ike} protocol as it is the most interesting from an AAL and security standpoint. % this part could maybe be moved to the introduction, not sure
