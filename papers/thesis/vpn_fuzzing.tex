%----------------------------------------------------------------
%
%  File    :  vpn_fuzzing.tex
%
%  Author  :  Benjamin Wunderling, TU Graz, Austria
% 
%  Created :  22 Feb 96
% 
%  Changed :  19 Feb 2004
% 
%----------------------------------------------------------------

\chapter{Fuzzing}

\label{chap:Fuzzing}

\section{Environment Setup} \label{sec:environment}
% describe VMs, IPsec server software, configuration etc
We ran all our fuzzing tests in the same virtual network setup we used for our automata learning, on the same Ubuntu 22.04 LTS distributions. We again designated one \ac{vm} as the initiator which would send the fuzzed messages and the other one as the responder to create a typical client-server setup. All settings on the used VMs remained the same as while learning to ensure that no discrepancies were introduced by different environment settings. The \ac{sut} was also the same Strongswan server used for learning. 

\subsection{Adapting the Model} \label{subsec:adapting_model}
While we had already successfully learned a (deterministic) model of the \ac{sul} when exposed to expected inputs, this proved to be not particularly useful for model-based fuzzing, as each fuzz case would be treated as new behavior. Instead we learned a new model, again with retransmission-filtering enabled, but this time also with an expanded input alphabet. We added an erroneous version of each input letter that maps to an \ac{ike} packet with some sort of error or malformation, as shown in Listing \ref{lst:inputal_2}. The goal was to learn the behavior of the \ac{sul} when exposed to typical errors or malformed packets that could arise during fuzzing, to be able to filter away as much uninteresting information as possible and focus on more unusual behavior. An example of such a malformed packet could be an incorrect length field, a wrong hash value or simply an unsupported \ac{sa} option. Since we had designed our mapper class in such a way as to allow for easy manipulation of packets, this was an easy change to implement. Some additional server responses had to be parsed correctly, but all in all, not much had to be changed. The resulting model can be seen in Figure \ref{fig:withfilterwitherrors} and was used as our reference model while testing.  

\begin{lstlisting}[float=h, caption=The Updated Input Alphabet, label=lst:inputal_2, numbers=none, language=python]
	input_al = ['sa_main', 'key_ex_main', 'authenticate', 'sa_quick', 'ack_quick', 'sa_main_err', 'key_ex_main_err', 'authenticate_err', 'sa_quick_err', 'ack_quick_err']
\end{lstlisting}


\subsection{Fuzzing Setup} \label{subsec:fuzz_setup}
% tools used
As we had already designed our mapper class in such a way as to allow for easy fuzzing, the only thing missing was a source of values to use for fuzzing. For this purpose, we used the open source fuzzing library boofuzz\footnote{https://github.com/jtpereyda/boofuzz}, which is a successor of the popular Sulley\footnote{https://github.com/OpenRCE/sulley} fuzzer. Additionally we implemented a very simple parser for the .dot files of the learned model, as well as a converter between .dot files and state machines.

% procedure --> 2 phases: p1 - prefiltering, p2 - boofuzz fuzz lists
The general procedure for model-based fuzzing is to fuzz the target system, while at the same time keeping track of the expected outputs on a reference model, to be able to identify new states and interesting behavior. While our fuzzer does follow this pattern, due to the \ac{ipsec}-\ac{ike}v1 protocol being rather complicated, fuzzing every possible field would be an immense task that goes far beyond the scope of this masters thesis. Instead, we implemented several techniques to limit the amount of fuzzing to be done in a way that aims to still maximize the chances of discovering new states and potential bugs. 

Firstly, instead of fuzzing every possible field of the protocol, we instead chose 5-10 key fields from each packet that looked to be the most impactful and representative for that type of message. We focused on length fields, \ac{sa} proposals and hashes / keys, but also added general fields, such as the responder / initiator cookies. All the chosen fields were added as parameters to their respective mapper class methods and default to their usual values. 

The next step was the run-generation phase in which we look to generate a set of runs consisting of input alphabet words, were one of the letters will be randomly chosen to be fuzzed. Our first idea was to go on random walks through the state machine and mirror the messages sent to the \ac{sut} as well, but the problem here at least for truely random walks was a lot of wasted queries in phase one and not enough state coverage in phase two. Therefore, since we had already generated a number of runs during model learning that guarantee state-coverage, we decided to simply repurpose those runs for fuzzing. The problem with this approach however, was that the resulting set of runs was rather large. So, in an effort to reduce the fuzzing space, we employed an additional filtering phase before the actual in-depth fuzzing. In this phase, we go through each run one by one and randomly designate one of its input alphabet letters as the fuzzing target. Then we test each parameter of that letter in the context of the run with a greatly reduced set of fuzz values and compare the results to the expected outcomes using our state machine. If new behaviour is found, the run and fuzz target passes the filtering. Runs in which no new behavior is discovered are discarded. This allows us to focus our resources on testing those configurations in which it is more likely to discover new behavior and therefore also bugs. 

Following the automatic filtering, we go over the results and manually check and remove / reduce the number of identical or not relevant cases. For example, we noticed that every run in which cookies were fuzzed led to new states, due to new cookies indicating a completely new connection and since we learned the model with static initiator cookies, this will always lead to a new state. 
Finally, we arrive at a list of 175 runs, compared to roughly ten times the number before filtering. The filtered list of runs can be found in Appendix TODO: APPENDIX.


% TODO: improvements for run-generation, potentially refine the model with new info


Phase two, take the (hopefully reduced) list of interesting runs and fuzz targets on those runs and apply actual in-depth fuzzing using boofuzz to generate our fuzz-cases for all but the most complicated of parameters

TODO: Diagram for fuzzing process
Placeholder for grafic
p\\
p\\
p\\
p\\
p\\
p\\
p\\
p\\
p\\
p\\
p\\
p\\
p\\
p\\
p\\
p\\
p\\
p\\
