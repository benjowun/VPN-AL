%----------------------------------------------------------------
%
%  File    :  vpn_conclusion.tex
%
%  Author  :  Benjamin Wunderling, TU Graz, Austria
% 
%----------------------------------------------------------------

\chapter{Conclusion}
\label{chap:Conclusion}

\subsection{Summary}
In this thesis, we learned behavioral models of two \ac{ipsec} server implementations, strongSwan and libreswan. We presented the learned models of both implementations, comparing them with respect to various metrics including runtime and the number of required queries. Our results show, that our learning setup succeeds in its goal of reliably learning models of the target \ac{ipsec} \ac{ike}v1 server implementations. We contrasted two popular model-learning algorithms $KV$ and $L^*$ and explained why we consider $KV$ to be better suited for our learning setup. Furthermore, we highlighted the difficulties that arose during model learning, such as issues with non-determinism, and presented our proposed solutions. Additionally, we demonstrated the usefulness of \ac{aal} from a testing standpoint by showcasing a Python cryptography library bug found during model learning. 

We used the learned models to perform model-based fuzzing of the \ac{ipsec} implementations under test. We presented the results of our fuzzer, highlighting the most interesting findings, most notably, two deviations from the RFC specification, as well as a potential deadlock. We recommend that the findings be thoroughly examined to ensure that they do not pose compatibility or security risks. Furthermore, we compared the various utilized input sequence-generation methods to each other and a random baseline. For our \acp{sut}, all non-baseline input sequence-generation methods discovered all findings. However, significant differences in the calculated fitness scores of the respective methods were observed, with the genetic algorithm-based method performing the best. As the used fitness score takes the state coverage into account, the genetic method will likely have the greatest chance at finding interesting behavior. However, from a pure runtime perspective, the search-based method was the most efficient for the \ac{sut} at hand. The filtering-based method was by far the slowest, with fuzzing of the generated input sequences taking almost 10 times as long as fuzzing the genetic-algorithm generated input sequences. While perhaps slightly more thorough, the comparable fitness score of the genetic-algorithm generated input sequences, combined with its significantly faster runtime fuzzing them, leads us to the conclusion, that of the tested methods, the genetic algorithm-based input sequence-generation method is the one best suited for further fuzzing work.

Overall, our findings highlight the importance of thorough testing and validation of network protocols and their implementations and show how new tools and techniques can be used to help accomplish that.

\subsection{Discussion}
Model learning and fuzzing was made more difficult due to implementation differences between libreswan and strongSwan. Perhaps the most significant such difference is the error handling. While strongSwan tends to send all expected informational error notification packets, libreswan, especially in phase one, does not. Additionally, while strongSwan destroys unfinished connections upon receiving an error, libreswan ignores most errors. This behavior forces us to implement a workaround for our \emph{reset} method for libreswan, using an additional SSH connection to manually reset the server. While functional in theory, in practice, such a connection is usually unrealistic in a real world black-box testing scenario, as communication to the server is usually limited to specific ports and root access is even more unlikely. Still, the learned libreswan models serve to showcase the implementation differences between the two not unrelated projects (both implementations share a common ancestor in FreeS/WAN). Furthermore, as the two implementations behave so differently, it is possible to identify them based on their learned models, and even simpler, their responses (or non-responses) to a set of informational requests. Additionally, analyzing and comparing the learned models helped increase our understanding of the intricacies of the \ac{ipsec} protocol, leading to the discovery of a potential libreswan deadlock. This demonstrates that model learning has considerable value, even beyond its security applications. It can serve as a useful tool for aiding our comprehension of complex protocols and software by offering an easily understandable, abstracted overview of the \ac{sul}.

Regarding the fuzzing of the two \acp{sut}, little to no differences in the number of discovered findings were observed between the utilized input sequence-generation methods. However, the fitness scores show that the genetic algorithm-based method outperforms the other methods with respect to coverage and runtime. Therefore, it is reasonable to assume, that the genetic method would discover more findings than the other methods if applied to a more vulnerable \ac{sut}. Of the discovered findings, the strongSwan exclusive \texttt{Authentication} transform field bug is likely to be the most disruptive, potentially making debugging connection establishments more difficult. While we believe a severe security impact to be unlikely, we still recommend to examine the presented findings, as any undocumented behavior can be a source of bugs and compatibility issues. 

\subsection{Future Work}
Regarding our \ac{ipsec} mapper class and model learning, future work could include support for more authentication methods, additional extensions and variable user-cookies. Additionally, it would be interesting to test the model-learning framework with further \ac{ipsec} implementations.

The developed fuzzing code can be applied to other protocols and implementations, simplifying potential future work testing additional \ac{ipsec} implementations and/or similar protocols. Especially a study on the effectiveness of the genetic algorithm-based input sequence-generation method compared to the other methods of input generation on various \acp{sut} could prove interesting. Additionally, more methods of input-sequence generation could be explored.